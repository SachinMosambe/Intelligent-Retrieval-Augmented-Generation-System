# IntelliRAG ğŸ§ 

**Intelligent Retrieval-Augmented Generation System**

A production-ready RAG system with advanced retrieval, cross-encoder reranking, and comprehensive RAGAS evaluation metrics.

---

## âœ¨ Features

- ğŸ” **Advanced Retrieval** - FAISS vector store with semantic search
- ğŸ¯ **Cross-Encoder Reranking** - MS-MARCO model for improved relevance
- ğŸ“Š **Query Expansion** - Automatic query variations for better recall
- ğŸ¤– **LLM Integration** - Meta-Llama 3.1 via Together AI
- ğŸ“ˆ **RAGAS Evaluation** - Comprehensive quality metrics
- ğŸ“„ **Multi-Format Support** - PDF, DOCX, TXT, images with OCR
- ğŸ”¬ **Explainability** - Retrieval visualization and source attribution

---

## ğŸš€ Quick Start

### Installation

```bash
# Clone repository
git clone https://github.com/yourusername/intellirag.git
cd intellirag

# Install dependencies
pip install -r requirements.txt

# Set up environment
echo "TOEGETHERAI_API_KEY=your_api_key_here" > .env
```

### Basic Usage

```python
from src.embedding import create_vector_store_enhanced
from src.generator import generate_response_enhanced
from src.loader import load_files
from src.retriever import search_vector_store_enhanced

# Load documents
documents = load_files(["./data/your_document.pdf"])

# Create vector store
vector_store = create_vector_store_enhanced(documents)

# Create retriever
retriever = search_vector_store_enhanced(vector_store)

# Ask question
result = generate_response_enhanced(retriever, "What is the main topic?")

print(f"Answer: {result['answer']}")
print(f"Sources: {result['sources']}")
```

---

## ğŸ“Š Evaluation

Run comprehensive RAGAS evaluation:

```python
from src.evaluation import RAGEvaluator

evaluator = RAGEvaluator(
    nq_file_path="./data/nq-train-sample.jsonl",
    num_questions=50,
    num_docs=100
)

evaluator.run_full_evaluation()
```

### Metrics

| Metric | Target | Description |
|--------|--------|-------------|
| Faithfulness | >0.9 | No hallucinations |
| Answer Relevancy | >0.8 | Addresses the question |
| Context Precision | >0.8 | Well-ranked results |
| Context Recall | >0.7 | Retrieved enough info |
| Context Relevancy | >0.8 | Context matches query |

---

## ğŸ“ Project Structure

```
intellirag/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ embedding.py           # Vector store creation
â”‚   â”œâ”€â”€ retriever.py           # Advanced retriever with reranking
â”‚   â”œâ”€â”€ generator.py           # LLM response generation
â”‚   â”œâ”€â”€ loader.py              # Document loader with OCR
â”‚   â”œâ”€â”€ evaluation.py          # RAGAS evaluation pipeline
â”‚   â”œâ”€â”€ explainability.py      # Visualization tools
â”‚   â””â”€â”€ test_data_loader.py    # NQ dataset loader
â”œâ”€â”€ data/                      # Documents and datasets
â”œâ”€â”€ venv/                      # Virtual environment
â”œâ”€â”€ app.py                     # Main application
â”œâ”€â”€ requirements.txt           # Dependencies
â”œâ”€â”€ .env                       # Environment variables
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

---

## âš™ï¸ Configuration

### Chunking Strategy
```python
chunk_size = 800        # Tokens per chunk
chunk_overlap = 200     # Overlap between chunks
```

### Retrieval Settings
```python
k = 10                  # Initial retrieval
top_n = 5              # After reranking
```

### LLM Settings
```python
model = "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo"
temperature = 0.1       # Low for factual answers
max_tokens = 512
```

---

## ğŸ”§ Advanced Features

### Explainability

```python
from src.explainability import RAGExplainer

explainer = RAGExplainer()

# Visualize retrieval scores
plt = explainer.visualize_retrieval_scores(docs, scores, query, top_n=5)
plt.show()

# Get source attribution
attribution = explainer.create_source_attribution_map(answer, sources)
```

### OCR Support

Automatically handles scanned PDFs and images:

```python
from src.loader import load_files

# Supports: .pdf, .docx, .txt, .png, .jpg, .tiff
documents = load_files([
    "scanned_document.pdf",
    "image.png",
    "text.docx"
])
```

---

## ğŸ“¦ Dependencies

Core libraries:
- `langchain` - RAG framework
- `langchain-openai` - LLM integration
- `langchain-community` - Document loaders
- `faiss-cpu` - Vector store
- `sentence-transformers` - Embeddings and reranking
- `ragas` - Evaluation metrics
- `pytesseract` - OCR engine
- `beautifulsoup4` - HTML parsing

See `requirements.txt` for complete list.

---

## ğŸ¯ Use Cases

### Document Q&A
Build intelligent question-answering systems over your documents.

### Knowledge Base
Create searchable knowledge bases with semantic understanding.

### Research Assistant
Retrieve and synthesize information from multiple sources.

### Customer Support
Answer customer queries using your documentation.

---

## ğŸ› ï¸ Development

### Setup Development Environment

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Install Tesseract (for OCR)
# Ubuntu/Debian
sudo apt-get install tesseract-ocr

# macOS
brew install tesseract

# Windows
# Download from: https://github.com/UB-Mannheim/tesseract/wiki
```

### Running Tests

```bash
# Test document loader
python -m src.test_data_loader

# Test complete pipeline
python -m src.evaluation
```

---

## ğŸ“ Environment Variables

Create a `.env` file:

```bash
# Required
TOEGETHERAI_API_KEY=your_together_ai_api_key

# Optional
OPENAI_API_KEY=your_openai_api_key  # If using OpenAI instead
```

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- Natural Questions dataset by Google AI
- RAGAS evaluation framework
- LangChain for RAG infrastructure
- Sentence Transformers for embeddings
- Together AI for LLM hosting

---

## ğŸ“¬ Contact

For questions or support, please open an issue on GitHub.

---

## ğŸš¦ Status Indicators

- ğŸŸ¢ Production Ready: All metrics above targets
- ğŸŸ¡ Good: Minor improvements needed
- ğŸ”´ Needs Work: Significant tuning required

---

